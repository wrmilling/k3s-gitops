# Server plan
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: k3s-server
  namespace: system-upgrade
spec:
  concurrency: 1
  cordon: true
  nodeSelector:
    matchExpressions:
    - key: node-role.kubernetes.io/master
      operator: In
      values:
      - "true"
    - {key: k3os.io/mode, operator: DoesNotExist}
    - {key: k3s-upgrade, operator: NotIn, values: ["disabled", "false"]}
    - key: kubernetes.io/arch
      operator: In
      values:
      - "amd64"
  serviceAccountName: system-upgrade
  tolerations:
    - {key: node-role.kubernetes.io/master, effect: NoSchedule, operator: Equal, value: "true"}
  upgrade:
    image: rancher/k3s-upgrade@sha256:70a238fdf8da99b99fcdb835f8162c9176e8078c170f5d6f349d3b38c3bfed7b
  channel: https://update.k3s.io/v1-release/channels/v1.24
---
# Agent plan
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: k3s-agent
  namespace: system-upgrade
  labels:
    k3s-upgrade: agent
spec:
  concurrency: 1
  channel: https://update.k3s.io/v1-release/channels/v1.24
  nodeSelector:
    matchExpressions:
      - {key: k3s-upgrade, operator: Exists}
      - {key: k3s-upgrade, operator: NotIn, values: ["disabled", "false"]}
      - {key: k3s.io/hostname, operator: Exists}
      - {key: k3os.io/mode, operator: DoesNotExist}
      - {key: node-role.kubernetes.io/master, operator: NotIn, values: ["true"]}
  serviceAccountName: system-upgrade

  # Specify which node taints should be tolerated by pods applying the upgrade.
  # Anything specified here is appended to the default of:
  # - {key: node.kubernetes.io/unschedulable, effect: NoSchedule, operator: Exists}
  tolerations:
    - {key: kubernetes.io/arch, effect: NoSchedule, operator: Equal, value: amd64}
    - {key: kubernetes.io/arch, effect: NoSchedule, operator: Equal, value: arm64}
    - {key: kubernetes.io/arch, effect: NoSchedule, operator: Equal, value: arm}
    - {key: arm, operator: Exists}

  prepare:
    # Since v0.5.0-m1 SUC will use the resolved version of the plan for the tag on the prepare container.
    # image: rancher/k3s-upgrade:v1.17.4-k3s1
    image: rancher/k3s-upgrade@sha256:70a238fdf8da99b99fcdb835f8162c9176e8078c170f5d6f349d3b38c3bfed7b
    args: ["prepare", "k3s-server"]
  # drain:
  #   force: true
  #   skipWaitForDeleteTimeout: 60 # set this to prevent upgrades from hanging on small clusters since k8s v1.18
  upgrade:
    image: rancher/k3s-upgrade@sha256:70a238fdf8da99b99fcdb835f8162c9176e8078c170f5d6f349d3b38c3bfed7b
